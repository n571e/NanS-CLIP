# -*- coding: utf-8 -*-
"""
LLM æ–‡æœ¬æ‰©å¢è„šæœ¬ã€‚

è¯»å–å·²æœ‰ annotations.jsonï¼Œå¯¹æ¯æ¡æ ‡æ³¨çš„ modern_chinese æè¿°
è°ƒç”¨çº¯æ–‡æœ¬ LLMï¼ˆqwen-turboï¼Œæ›´å¿«æ›´ä¾¿å®œï¼‰ç”ŸæˆåŒä¹‰æ”¹å†™å˜ä½“ï¼Œ
å°†è®­ç»ƒæ–‡æœ¬ä» ~340 æ¡æ‰©å¢è‡³ ~1000+ æ¡ã€‚

ç”¨æ³•:
    python scripts/augment_texts.py
    python scripts/augment_texts.py --limit 5     # æµ‹è¯•æ¨¡å¼
    python scripts/augment_texts.py --variants 3   # æ¯æ¡ç”Ÿæˆ 3 ä¸ªå˜ä½“
"""

import argparse
import json
import os
import sys
import time
from pathlib import Path

try:
    from openai import OpenAI
except ImportError:
    print("âŒ ç¼ºå°‘ openai åº“ï¼Œè¯·å…ˆè¿è¡Œ: pip install openai")
    sys.exit(1)

# ============ é…ç½® ============
PROJECT_ROOT = Path(__file__).resolve().parent.parent
ANNOTATION_FILE = PROJECT_ROOT / "data" / "annotations.json"
OUTPUT_FILE = PROJECT_ROOT / "data" / "annotations_augmented.json"

API_KEY = os.getenv("DASHSCOPE_API_KEY", "")
API_DELAY = 0.8  # ç§’ï¼Œqwen-turbo é™æµå®½æ¾

REWRITE_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸­å›½å†å²æ–‡åŒ–é¢†åŸŸçš„æ–‡æœ¬æ”¹å†™ä¸“å®¶ã€‚è¯·å¯¹ä»¥ä¸‹æè¿°è¿›è¡ŒåŒä¹‰æ”¹å†™ï¼š

åŸå§‹æè¿°ï¼š{text}
å›¾ç‰‡æ ‡é¢˜ï¼š{title}

è¯·ç”Ÿæˆ {n} æ¡ä¸åŒé£æ ¼çš„æ”¹å†™ç‰ˆæœ¬ï¼š
1. ä¿ç•™æ ¸å¿ƒè¯­ä¹‰å’Œå…³é”®ä¿¡æ¯ï¼ˆæœä»£ã€åœ°ç‚¹ã€äººç‰©ã€æŠ€æ³•ç­‰ï¼‰ï¼Œä½†å˜æ¢å¥å¼å’Œç”¨è¯
2. æ¯æ¡æ”¹å†™é•¿åº¦åœ¨ 40-120 å­—ä¹‹é—´
3. å¯ä»¥é€‚å½“è°ƒæ•´å™è¿°è§’åº¦ï¼ˆå¦‚ä»"ç”»é¢å±•ç¤º"æ”¹ä¸º"ä½œå“æç»˜"ï¼‰

è¯·ä¸¥æ ¼ä»¥ JSON æ•°ç»„æ ¼å¼è¾“å‡ºï¼Œä¾‹å¦‚ï¼š
[
  "æ”¹å†™ç‰ˆæœ¬1...",
  "æ”¹å†™ç‰ˆæœ¬2..."
]"""


def init_client():
    return OpenAI(
        api_key=API_KEY,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )


def augment_text(client, text, title, n_variants=2):
    """è°ƒç”¨ LLM å¯¹ä¸€æ¡æ–‡æœ¬ç”Ÿæˆ n ä¸ªåŒä¹‰æ”¹å†™å˜ä½“"""
    prompt = REWRITE_PROMPT.format(text=text, title=title, n=n_variants)

    try:
        response = client.chat.completions.create(
            model="qwen-turbo",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯æ–‡æœ¬æ”¹å†™ä¸“å®¶ï¼Œåªè¾“å‡º JSON æ•°ç»„ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.8,  # ç¨é«˜æ¸©åº¦å¢åŠ å¤šæ ·æ€§
            max_tokens=500,
        )
        content = response.choices[0].message.content.strip()

        # æå– JSON æ•°ç»„
        if "[" in content:
            content = content[content.index("["):content.rindex("]") + 1]
        variants = json.loads(content)

        if isinstance(variants, list):
            return [v for v in variants if isinstance(v, str) and len(v) > 10]
        return []

    except json.JSONDecodeError:
        print(f"      âš ï¸ JSON è§£æå¤±è´¥")
        return []
    except Exception as e:
        print(f"      âŒ API å¤±è´¥: {str(e)[:60]}")
        return []


def main():
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', line_buffering=True)

    parser = argparse.ArgumentParser(description="LLM æ–‡æœ¬æ‰©å¢")
    parser.add_argument("--annotation", type=str, default=str(ANNOTATION_FILE))
    parser.add_argument("--output", type=str, default=str(OUTPUT_FILE))
    parser.add_argument("--variants", type=int, default=2, help="æ¯æ¡ç”Ÿæˆå‡ ä¸ªå˜ä½“ (é»˜è®¤ 2)")
    parser.add_argument("--limit", type=int, default=None, help="åªå¤„ç†å‰ N æ¡ (æµ‹è¯•ç”¨)")
    args = parser.parse_args()

    # æ£€æŸ¥ API Key
    if not API_KEY:
        print("âŒ è¯·è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
        print("   export DASHSCOPE_API_KEY=your_key  (Linux/Mac)")
        print("   $env:DASHSCOPE_API_KEY='your_key'  (PowerShell)")
        sys.exit(1)

    # åŠ è½½æ ‡æ³¨
    annotation_file = Path(args.annotation)
    with open(annotation_file, "r", encoding="utf-8") as f:
        annotations = json.load(f)
    print(f"ğŸ“‹ åŠ è½½ {len(annotations)} æ¡æ ‡æ³¨")

    if args.limit:
        annotations = annotations[:args.limit]
        print(f"   [æµ‹è¯•æ¨¡å¼] åªå¤„ç†å‰ {args.limit} æ¡")

    # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
    print("ğŸ”§ åˆå§‹åŒ– qwen-turbo å®¢æˆ·ç«¯...")
    client = init_client()

    # åŠ è½½å·²æœ‰æ‰©å¢ç»“æœï¼ˆæ–­ç‚¹ç»­åšï¼‰
    output_file = Path(args.output)
    augmented = []
    processed_files = set()
    if output_file.exists():
        with open(output_file, "r", encoding="utf-8") as f:
            augmented = json.load(f)
            processed_files = {a["filename"] for a in augmented}
        print(f"ğŸ“‚ å·²æœ‰ {len(augmented)} æ¡æ‰©å¢ç»“æœï¼Œæ–­ç‚¹ç»­åš")

    original_count = len(augmented)
    new_count = 0

    for i, ann in enumerate(annotations):
        filename = ann.get("filename", "")

        # è·³è¿‡å·²å¤„ç†çš„
        if filename in processed_files:
            continue

        text = ann.get("modern_chinese", "")
        title = ann.get("title", filename)

        if not text or len(text) < 10:
            # æ— æœ‰æ•ˆæ–‡æœ¬ï¼ŒåŸæ ·ä¿ç•™
            augmented.append(ann)
            continue

        print(f"[{i+1}/{len(annotations)}] æ‰©å¢: {filename}")
        print(f"    åŸæ–‡: {text[:50]}...")

        # ç”Ÿæˆå˜ä½“
        variants = augment_text(client, text, title, n_variants=args.variants)

        # åŸå§‹æ¡ç›®ä¿ç•™
        augmented.append(ann)

        # ä¸ºæ¯ä¸ªå˜ä½“åˆ›å»ºæ–°æ¡ç›®
        for vi, variant in enumerate(variants):
            new_ann = ann.copy()
            new_ann["modern_chinese"] = variant
            new_ann["augmented"] = True  # æ ‡è®°ä¸ºæ‰©å¢æ•°æ®
            new_ann["augment_source"] = filename
            new_ann["augment_variant"] = vi + 1
            augmented.append(new_ann)
            print(f"    âœ… å˜ä½“{vi+1}: {variant[:50]}...")

        new_count += 1

        # æ¯ 10 æ¡ä¿å­˜ä¸€æ¬¡
        if new_count % 10 == 0:
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(augmented, f, ensure_ascii=False, indent=2)
            print(f"    ğŸ’¾ å·²ä¿å­˜ ({len(augmented)} æ¡)")

        time.sleep(API_DELAY)

    # æœ€ç»ˆä¿å­˜
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(augmented, f, ensure_ascii=False, indent=2)

    # ç»Ÿè®¡
    orig_texts = sum(1 for a in augmented if not a.get("augmented"))
    aug_texts = sum(1 for a in augmented if a.get("augmented"))

    print(f"\n{'='*50}")
    print(f"ğŸ‰ æ–‡æœ¬æ‰©å¢å®Œæˆï¼")
    print(f"   åŸå§‹æ ‡æ³¨: {orig_texts} æ¡")
    print(f"   æ–°å¢å˜ä½“: {aug_texts} æ¡")
    print(f"   æ€»è®¡: {len(augmented)} æ¡")
    print(f"   è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"{'='*50}")

    print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥: ç”¨æ‰©å¢åçš„æ ‡æ³¨é‡å»ºæ•°æ®é›†")
    print(f"   python scripts/build_dataset.py --annotation {output_file}")


if __name__ == "__main__":
    main()
