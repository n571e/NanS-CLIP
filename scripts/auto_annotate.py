# -*- coding: utf-8 -*-
"""
ä½¿ç”¨é€šä¹‰åƒé—® VLï¼ˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼‰è‡ªåŠ¨ä¸ºå›¾ç‰‡ç”Ÿæˆå¤šç§æ–‡æœ¬æè¿°ã€‚

å‰ç½®æ¡ä»¶:
    1. å·²è¿è¡Œ scrape_wikimedia.py ä¸‹è½½å›¾ç‰‡åˆ° data/images/
    2. å·²æœ‰ data/image_metadata.jsonl
    3. å·²è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY æˆ–ç›´æ¥ä¿®æ”¹ä¸‹æ–¹ API_KEY

ä½¿ç”¨æ–¹æ³•:
    # è®¾ç½® API Keyï¼ˆäºŒé€‰ä¸€ï¼‰
    set DASHSCOPE_API_KEY=sk-xxx
    # æˆ–ç›´æ¥ä¿®æ”¹è„šæœ¬ä¸­çš„ API_KEY å˜é‡

    conda activate pytorch
    cd d:/Desktop/CV/CLIP/NanS-CLIP

    # æµ‹è¯•æ¨¡å¼ï¼ˆåªå¤„ç†å‰ 3 å¼ ï¼‰
    python scripts/auto_annotate.py --limit 3

    # æ­£å¼è¿è¡Œï¼ˆå¤„ç†æ‰€æœ‰å›¾ç‰‡ï¼‰
    python scripts/auto_annotate.py

è¾“å‡º:
    data/annotations.json   æ¯å¼ å›¾çš„å¤šç§æ–‡æœ¬æè¿°
"""

import os
import sys
import json
import time
import base64
import argparse
from pathlib import Path

# ============ é…ç½® ============
API_KEY = os.getenv("DASHSCOPE_API_KEY", "sk-67322cb9af1c4de493fcc371d3af9493")
API_BASE = "https://dashscope.aliyuncs.com/compatible-mode/v1"
VLM_MODEL = "qwen-vl-plus"       # è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆçœ‹å›¾ç”Ÿæ–‡ï¼‰
LLM_MODEL = "qwen-turbo"         # çº¯æ–‡æœ¬æ¨¡å‹ï¼ˆæ”¹å†™å¤æ–‡ï¼‰

IMAGE_DIR = Path("data/images")
METADATA_FILE = Path("data/image_metadata.jsonl")
OUTPUT_FILE = Path("data/annotations.json")

# API è°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰ï¼Œé¿å…è§¦å‘é¢‘ç‡é™åˆ¶
API_DELAY = 1.5


def init_client():
    """åˆå§‹åŒ– OpenAI å…¼å®¹å®¢æˆ·ç«¯"""
    try:
        from openai import OpenAI
    except ImportError:
        print("âŒ ç¼ºå°‘ openai åº“ï¼Œæ­£åœ¨å®‰è£…...")
        os.system(f"{sys.executable} -m pip install openai")
        from openai import OpenAI

    return OpenAI(api_key=API_KEY, base_url=API_BASE)


def image_to_base64(image_path: Path) -> str:
    """å°†å›¾ç‰‡è½¬ä¸º base64 å­—ç¬¦ä¸²"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")


def get_image_mime(image_path: Path) -> str:
    """æ ¹æ®åç¼€æ¨æ–­ MIME ç±»å‹"""
    suffix = image_path.suffix.lower()
    return {
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".png": "image/png",
        ".webp": "image/webp",
        ".tiff": "image/tiff",
        ".tif": "image/tiff",
    }.get(suffix, "image/jpeg")


def infer_category(meta: dict) -> str:
    """
    æ ¹æ® title / description / categories ä¸­çš„å…³é”®è¯è‡ªåŠ¨æ¨æ–­å›¾ç‰‡ç±»åˆ«ã€‚
    è¿”å›: "figure" | "genre_scene" | "calligraphy" | "artifact" |
          "architecture" | "map" | "painting" | "general"
    åŒ¹é…é¡ºåºï¼šç»†åˆ†ç±»ä¼˜å…ˆ â†’ å¤§ç±»å…œåº•
    """
    text = " ".join([
        meta.get("title", ""),
        meta.get("description", ""),
        " ".join(meta.get("categories", [])),
    ]).lower()

    # ---- ç»†åˆ†ç±»ä¼˜å…ˆåŒ¹é… ----
    figure_kw = ["portrait", "figure", "lady", "emperor", "official",
                 "scholar", "monk", "child", "rider", "court",
                 "äººç‰©", "ä»•å¥³", "ä¾å¥³", "å¸", "åƒ", "ç½—æ±‰"]
    scene_kw = ["festival", "market", "banquet", "ceremony", "procession",
                "daily life", "trade", "performance", "gathering",
                "æ¸…æ˜", "ä¸Šå…ƒ", "é¾™èˆŸ", "èš•ç»‡", "è´§éƒ", "è€•ç»‡", "å²æœ"]
    callig_kw = ["calligraphy", "inscription", "rubbing", "stele",
                 "ä¹¦æ³•", "ç¢‘", "å¸–", "æ‹“ç‰‡", "é¢˜è·‹", "å¢¨è¿¹"]

    for kw in figure_kw:
        if kw in text:
            return "figure"
    for kw in scene_kw:
        if kw in text:
            return "genre_scene"
    for kw in callig_kw:
        if kw in text:
            return "calligraphy"

    # ---- å¤§ç±»åŒ¹é… ----
    artifact_kw = ["porcelain", "ceramic", "bowl", "vase", "jade",
                   "bronze", "pillow", "cup", "plate", "kiln",
                   "celadon", "lacquer", "glaze", "vessel",
                   "ç“·", "å™¨", "çª‘", "é‡‰", "ç¢—", "å£¶"]
    arch_kw = ["pagoda", "temple", "palace", "bridge", "gate",
               "tower", "pavilion", "tomb", "ruins", "city",
               "wall", "garden", "mosque", "monastery",
               "å¡”", "å®«", "æ¡¥", "æ®¿", "å¯º", "åº™", "äº­"]
    map_kw = ["map", "atlas", "plan", "åœ°å›¾", "èˆ†å›¾", "å¿—"]
    painting_kw = ["painting", "scroll", "landscape", "ink", "silk",
                   "album", "bamboo", "flower", "bird", "mountain",
                   "fan", "handscroll", "hanging",
                   "ç”»", "å›¾", "å·", "ç»¢", "å†Œé¡µ"]

    for kw in artifact_kw:
        if kw in text:
            return "artifact"
    for kw in arch_kw:
        if kw in text:
            return "architecture"
    for kw in map_kw:
        if kw in text:
            return "map"
    for kw in painting_kw:
        if kw in text:
            return "painting"
    return "general"


# ---------- åˆ†ç±»åˆ« Prompt æ¨¡æ¿ ----------

_CATEGORY_INSTRUCTIONS = {
    "figure": """è¯·ç‰¹åˆ«å…³æ³¨ä»¥ä¸‹äººç‰©ç»†èŠ‚ï¼š
- äººç‰©èº«ä»½ç‰¹å¾ï¼ˆå¦‚è¡£å† æœé¥°ã€å¤´é¥°ã€é…é¥°æ‰€æš—ç¤ºçš„é˜¶å±‚ä¸èº«ä»½ï¼‰
- å§¿æ€åŠ¨ä½œä¸è¡¨æƒ…ç¥éŸµ
- äººç‰©ä¹‹é—´çš„äº’åŠ¨å…³ç³»ä¸ç”»é¢å™äº‹""",

    "genre_scene": """è¯·ç‰¹åˆ«å…³æ³¨ä»¥ä¸‹é£ä¿—åœºæ™¯ç»†èŠ‚ï¼š
- åœºæ™¯æ‰€åæ˜ çš„ç¤¾ä¼šæ´»åŠ¨ç±»å‹ï¼ˆå¦‚èŠ‚åº†ã€é›†å¸‚ã€å®´é¥®ã€è€•ç»‡ï¼‰
- æ—¶ä»£èƒŒæ™¯çº¿ç´¢ï¼ˆæœé¥°ã€å™¨å…·ã€å»ºç­‘é£æ ¼æ‰€æŒ‡å‘çš„å†å²æ—¶æœŸï¼‰
- ç”»é¢ä¸­çš„äººç¾¤åˆ†å¸ƒã€ç©ºé—´çºµæ·±ä¸å™äº‹ç»“æ„""",

    "calligraphy": """è¯·ç‰¹åˆ«å…³æ³¨ä»¥ä¸‹ä¹¦æ³•ç»†èŠ‚ï¼š
- ä¹¦ä½“ç±»å‹ï¼ˆæ¥·ã€è¡Œã€è‰ã€éš¶ã€ç¯†ï¼‰
- ç”¨ç¬”ç‰¹å¾ï¼ˆå¦‚ä¸­é”‹/ä¾§é”‹ã€ææŒ‰é¡¿æŒ«ã€å¢¨è‰²å˜åŒ–ï¼‰
- æ–‡æœ¬å†…å®¹æ¦‚è¦ä¸ä¹¦å†™è€…ä¿¡æ¯""",

    "painting": """è¯·ç‰¹åˆ«å…³æ³¨ä»¥ä¸‹è§†è§‰ç»†èŠ‚ï¼š
- æ„å›¾æ‰‹æ³•ï¼ˆå¦‚ç•™ç™½ã€ä¸‰è¿œæ³•ã€å¯¹è§’æ„å›¾ï¼‰
- ç”¨ç¬”æŠ€æ³•ï¼ˆå¦‚çš´æ³•ç±»å‹ã€çº¿æ¡ç²—ç»†ã€å¢¨è‰²æµ“æ·¡ï¼‰
- ç”»é¢æ„å¢ƒä¸æƒ…æ„Ÿè¡¨è¾¾""",

    "artifact": """è¯·ç‰¹åˆ«å…³æ³¨ä»¥ä¸‹ç»†èŠ‚ï¼š
- å™¨å‹ç‰¹å¾ï¼ˆå¦‚å½¢åˆ¶ã€å°ºå¯¸æ¯”ä¾‹ã€é€ å‹é£æ ¼ï¼‰
- é‡‰è‰²ä¸çº¹é¥°ï¼ˆå¦‚å†°è£‚çº¹ã€è²ç“£çº¹ã€åˆ»èŠ±ï¼‰
- å·¥è‰ºæ°´å¹³ä¸ä¿å­˜çŠ¶æ€""",

    "architecture": """è¯·ç‰¹åˆ«å…³æ³¨ä»¥ä¸‹ç»†èŠ‚ï¼š
- å»ºç­‘å½¢åˆ¶ï¼ˆå¦‚æ­‡å±±é¡¶ã€é‡æªã€æ–—æ‹±ï¼‰
- ç©ºé—´å¸ƒå±€ä¸å‘¨è¾¹ç¯å¢ƒå…³ç³»
- å†å²é—å­˜ä¸ç°ä»£ä¿®å¤ç—•è¿¹""",

    "map": """è¯·ç‰¹åˆ«å…³æ³¨ä»¥ä¸‹ç»†èŠ‚ï¼š
- åœ°å›¾æ‰€ç¤ºçš„åœ°ç†èŒƒå›´å’Œä¸»è¦åœ°æ ‡
- æ ‡æ³¨æ–‡å­—ä¸ç©ºé—´æ–¹ä½å…³ç³»
- ä¸å—å®‹ä¸´å®‰ï¼ˆä»Šæ­å·ï¼‰çš„åœ°ç†å…³è”""",

    "general": """è¯·å…³æ³¨ç”»é¢ä¸­çš„ä¸»è¦è§†è§‰å…ƒç´ ã€è‰²å½©ç‰¹å¾å’Œæ–‡åŒ–æ„ä¹‰ã€‚""",
}


def build_vlm_prompt(meta: dict) -> str:
    """
    æ ¹æ® metadata æ„å»º VLM promptï¼ˆç±»åˆ«è‡ªé€‚åº”ç‰ˆæœ¬ï¼‰ã€‚
    ä¼šå…ˆè‡ªåŠ¨æ¨æ–­å›¾ç‰‡ç±»åˆ«ï¼Œç„¶åä½¿ç”¨ä¸åŒçš„ç»†ç²’åº¦æŒ‡ä»¤æ¨¡æ¿ã€‚
    """
    context_parts = []

    era = meta.get("era", "")
    category = meta.get("category", "") or infer_category(meta)
    title = meta.get("title", "")
    artist = meta.get("artist", "")
    description = meta.get("description", "")

    # ä» Wikimedia çš„ categories æ¨æ–­æ—¶ä»£å’Œç±»å‹
    categories = meta.get("categories", [])
    categories_str = ", ".join(categories[:5]) if categories else ""

    if title:
        context_parts.append(f"è¿™å¹…ä½œå“çš„æ ‡é¢˜/åç§°æ˜¯ï¼š{title}")
    if era:
        context_parts.append(f"å¹´ä»£ï¼š{era}")
    if artist:
        context_parts.append(f"ä½œè€…ï¼š{artist}")
    if category:
        context_parts.append(f"ç±»åˆ«ï¼š{category}")
    if description:
        context_parts.append(f"å·²çŸ¥ä¿¡æ¯ï¼š{description[:200]}")
    if categories_str:
        context_parts.append(f"ç›¸å…³æ ‡ç­¾ï¼š{categories_str}")

    context = "\n".join(context_parts) if context_parts else "ï¼ˆæ— å·²çŸ¥èƒŒæ™¯ä¿¡æ¯ï¼‰"

    # æ ¹æ®æ¨æ–­ç±»åˆ«é€‰æ‹©ç»†ç²’åº¦æŒ‡ä»¤
    cat_key = infer_category(meta) if not meta.get("category") else category
    extra_instruction = _CATEGORY_INSTRUCTIONS.get(cat_key, _CATEGORY_INSTRUCTIONS["general"])

    return f"""ä½ æ˜¯ä¸€ä½å—å®‹å†å²ä¸è‰ºæœ¯ç ”ç©¶ä¸“å®¶ã€‚ä»¥ä¸‹æ˜¯å…³äºè¿™å¹…å›¾åƒçš„èƒŒæ™¯ä¿¡æ¯ï¼š

{context}

{extra_instruction}

è¯·æ ¹æ®å›¾åƒå†…å®¹å’ŒèƒŒæ™¯ä¿¡æ¯ï¼Œç”Ÿæˆä»¥ä¸‹ 3 ç§æ–‡æœ¬æè¿°ï¼š

1. **ç°ä»£ä¸­æ–‡æè¿°**ï¼ˆmodern_chineseï¼‰ï¼š50-100å­—ï¼Œå®¢è§‚æè¿°ç”»é¢å†…å®¹ï¼ŒåŒ…å«è§†è§‰å…ƒç´ ï¼ˆæ„å›¾ã€è‰²å½©ã€ç‰©è±¡ï¼‰å’Œæ–‡åŒ–æ„ä¹‰ã€‚
2. **å¤æ–‡é£æ ¼æè¿°**ï¼ˆancient_styleï¼‰ï¼š30-80å­—ï¼Œæ¨¡ä»¿å®‹ä»£ç¬”è®°ä½“ï¼ˆå¦‚ã€Šæ¢¦æ¢å½•ã€‹é£æ ¼ï¼‰ï¼Œç”¨æ–‡è¨€æ–‡æè¿°ç”»é¢ã€‚
3. **æ£€ç´¢å…³é”®è¯**ï¼ˆkeywordsï¼‰ï¼š5-8ä¸ªç”¨é€—å·åˆ†éš”çš„å…³é”®è¯ï¼Œæ¶µç›–æœä»£ã€é¢˜æã€æŠ€æ³•ã€åœ°ç‚¹ç­‰ç»´åº¦ã€‚

è¯·ä¸¥æ ¼ä»¥ JSON æ ¼å¼è¾“å‡ºï¼Œç¤ºä¾‹ï¼š
{{
  "modern_chinese": "è¿™å¹…å—å®‹å±±æ°´ç”»æç»˜äº†è¥¿æ¹–çƒŸæ³¢æµ©æ¸ºçš„æ™¯è‰²...",
  "ancient_style": "æ¹–å±±æ¸…è¿œï¼ŒçƒŸæ³¢æµ©æ¸ºï¼ŒèˆŸæ¥«å¾€æ¥å¦‚ç»‡...",
  "keywords": "å—å®‹, å±±æ°´ç”», è¥¿æ¹–, é’ç»¿å±±æ°´, ç»¢æœ¬è®¾è‰²"
}}"""


def call_vlm(client, image_path: Path, prompt: str) -> dict:
    """è°ƒç”¨é€šä¹‰åƒé—® VLï¼Œè¾“å…¥å›¾ç‰‡+æ–‡å­—ï¼Œè¿”å›ç»“æ„åŒ–æè¿°"""
    b64 = image_to_base64(image_path)
    mime = get_image_mime(image_path)

    try:
        response = client.chat.completions.create(
            model=VLM_MODEL,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{mime};base64,{b64}"
                            }
                        },
                        {
                            "type": "text",
                            "text": prompt
                        }
                    ]
                }
            ],
            temperature=0.7,
            max_tokens=800,
        )

        text = response.choices[0].message.content.strip()

        # å°è¯•è§£æ JSONï¼ˆå¤„ç†å¯èƒ½çš„ markdown ä»£ç å—åŒ…è£¹ï¼‰
        if "```json" in text:
            text = text.split("```json")[1].split("```")[0].strip()
        elif "```" in text:
            text = text.split("```")[1].split("```")[0].strip()

        return json.loads(text)

    except json.JSONDecodeError:
        print(f"    âš ï¸ JSON è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬ä½œä¸ºæè¿°")
        return {
            "modern_chinese": text[:200] if text else "æè¿°ç”Ÿæˆå¤±è´¥",
            "ancient_style": "",
            "keywords": ""
        }
    except Exception as e:
        print(f"    âŒ VLM è°ƒç”¨å¤±è´¥: {e}")
        return None


def load_metadata() -> dict:
    """åŠ è½½ image_metadata.jsonlï¼Œè¿”å› filename -> metadata çš„æ˜ å°„"""
    meta_map = {}
    if METADATA_FILE.exists():
        with open(METADATA_FILE, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                entry = json.loads(line)
                fname = entry.get("filename", "")
                if fname:
                    meta_map[fname] = entry
    return meta_map


def get_all_images() -> list:
    """è·å– data/images/ ä¸‹æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶"""
    exts = {".jpg", ".jpeg", ".png", ".webp", ".tiff", ".tif"}
    images = []
    if IMAGE_DIR.exists():
        for p in sorted(IMAGE_DIR.iterdir()):
            if p.suffix.lower() in exts and p.is_file():
                images.append(p)
    return images


def main():
    import sys
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    parser = argparse.ArgumentParser(description="VLM è‡ªåŠ¨æ ‡æ³¨å—å®‹æ–‡åŒ–å›¾ç‰‡")
    parser.add_argument("--limit", type=int, default=None, help="åªå¤„ç†å‰ N å¼ å›¾ç‰‡ï¼ˆæµ‹è¯•ç”¨ï¼‰")
    parser.add_argument("--skip-existing", action="store_true", default=True, help="è·³è¿‡å·²æ ‡æ³¨çš„å›¾ç‰‡")
    args = parser.parse_args()

    # æ£€æŸ¥ API Key
    if not API_KEY or API_KEY == "YOUR_API_KEY_HERE":
        print("âŒ è¯·è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡æˆ–ä¿®æ”¹è„šæœ¬ä¸­çš„ API_KEY")
        print("   è·å–åœ°å€: https://bailian.console.aliyun.com/")
        sys.exit(1)

    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    print("ğŸ”§ åˆå§‹åŒ– API å®¢æˆ·ç«¯...")
    client = init_client()

    # åŠ è½½ metadata
    meta_map = load_metadata()
    print(f"ğŸ“‹ åŠ è½½ metadata: {len(meta_map)} æ¡è®°å½•")

    # è·å–å›¾ç‰‡åˆ—è¡¨
    images = get_all_images()
    if not images:
        print(f"âŒ data/images/ ç›®å½•ä¸‹æ²¡æœ‰å›¾ç‰‡")
        print(f"   è¯·å…ˆè¿è¡Œ: python scripts/scrape_wikimedia.py")
        sys.exit(1)

    if args.limit:
        images = images[:args.limit]
    print(f"ğŸ–¼ï¸ å¾…å¤„ç†å›¾ç‰‡: {len(images)} å¼ \n")

    # åŠ è½½å·²æœ‰æ ‡æ³¨ï¼ˆæ”¯æŒæ–­ç‚¹ç»­åšï¼‰
    existing = {}
    if OUTPUT_FILE.exists():
        with open(OUTPUT_FILE, "r", encoding="utf-8") as f:
            existing_list = json.load(f)
            for entry in existing_list:
                existing[entry.get("filename", "")] = entry
        print(f"ğŸ“‚ å·²æœ‰ {len(existing)} æ¡æ ‡æ³¨ï¼Œæ–­ç‚¹ç»­åš\n")

    results = list(existing.values())
    new_count = 0

    for i, img_path in enumerate(images):
        filename = img_path.name

        # è·³è¿‡å·²å¤„ç†çš„
        if args.skip_existing and filename in existing:
            continue

        print(f"[{i+1}/{len(images)}] æ ‡æ³¨: {filename}")

        # è·å– metadataï¼ˆå¯èƒ½æ²¡æœ‰ï¼Œåˆ™ç”¨é»˜è®¤å€¼ï¼‰
        meta = meta_map.get(filename, {"title": filename, "description": ""})

        # æ„å»º prompt å¹¶è°ƒç”¨ VLM
        prompt = build_vlm_prompt(meta)
        vlm_result = call_vlm(client, img_path, prompt)

        if vlm_result is None:
            print(f"    â­ï¸ è·³è¿‡ï¼ˆè°ƒç”¨å¤±è´¥ï¼‰")
            continue

        # ç»„è£…æ ‡æ³¨ç»“æœ
        annotation = {
            "filename": filename,
            "image_path": str(img_path),
            "title": meta.get("title", filename),
            "era": meta.get("era", ""),
            "category": meta.get("category", ""),
            "source": meta.get("source", ""),
            "modern_chinese": vlm_result.get("modern_chinese", ""),
            "ancient_style": vlm_result.get("ancient_style", ""),
            "keywords": vlm_result.get("keywords", ""),
        }

        results.append(annotation)
        new_count += 1
        print(f"    âœ… ç°ä»£: {annotation['modern_chinese'][:50]}...")
        print(f"    âœ… å¤æ–‡: {annotation['ancient_style'][:50]}...")

        # æ¯å¤„ç† 5 å¼ ä¿å­˜ä¸€æ¬¡ï¼ˆé˜²æ­¢ä¸­æ–­ä¸¢å¤±ï¼‰
        if new_count % 5 == 0:
            with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"    ğŸ’¾ è¿›åº¦ä¿å­˜ï¼ˆ{len(results)} æ¡ï¼‰")

        # API è°ƒç”¨é—´éš”
        time.sleep(API_DELAY)

    # æœ€ç»ˆä¿å­˜
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ‰ æ ‡æ³¨å®Œæˆï¼")
    print(f"   æ–°å¢æ ‡æ³¨: {new_count} æ¡")
    print(f"   æ€»è®¡æ ‡æ³¨: {len(results)} æ¡")
    print(f"   è¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE.resolve()}")

    # æ‰“å°æ ·ä¾‹
    if results:
        sample = results[-1]
        print(f"\nğŸ“ æœ€åä¸€æ¡æ ·ä¾‹:")
        print(f"   æ–‡ä»¶: {sample['filename']}")
        print(f"   ç°ä»£: {sample['modern_chinese'][:80]}")
        print(f"   å¤æ–‡: {sample['ancient_style'][:80]}")
        print(f"   å…³é”®è¯: {sample['keywords']}")


if __name__ == "__main__":
    main()
