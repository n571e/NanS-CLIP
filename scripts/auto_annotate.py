# -*- coding: utf-8 -*-
"""
ä½¿ç”¨é€šä¹‰åƒé—® VLï¼ˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼‰è‡ªåŠ¨ä¸ºå›¾ç‰‡ç”Ÿæˆå¤šç§æ–‡æœ¬æè¿°ã€‚

å‰ç½®æ¡ä»¶:
    1. å·²è¿è¡Œ scrape_wikimedia.py ä¸‹è½½å›¾ç‰‡åˆ° data/images/
    2. å·²æœ‰ data/image_metadata.jsonl
    3. å·²è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY æˆ–ç›´æ¥ä¿®æ”¹ä¸‹æ–¹ API_KEY

ä½¿ç”¨æ–¹æ³•:
    # è®¾ç½® API Keyï¼ˆäºŒé€‰ä¸€ï¼‰
    set DASHSCOPE_API_KEY=sk-xxx
    # æˆ–ç›´æ¥ä¿®æ”¹è„šæœ¬ä¸­çš„ API_KEY å˜é‡

    conda activate pytorch
    cd d:/Desktop/CV/CLIP/NanS-CLIP

    # æµ‹è¯•æ¨¡å¼ï¼ˆåªå¤„ç†å‰ 3 å¼ ï¼‰
    python scripts/auto_annotate.py --limit 3

    # æ­£å¼è¿è¡Œï¼ˆå¤„ç†æ‰€æœ‰å›¾ç‰‡ï¼‰
    python scripts/auto_annotate.py

è¾“å‡º:
    data/annotations.json   æ¯å¼ å›¾çš„å¤šç§æ–‡æœ¬æè¿°
"""

import os
import sys
import json
import time
import base64
import argparse
from pathlib import Path

# ============ é…ç½® ============
API_KEY = os.getenv("DASHSCOPE_API_KEY", "sk-67322cb9af1c4de493fcc371d3af9493")
API_BASE = "https://dashscope.aliyuncs.com/compatible-mode/v1"
VLM_MODEL = "qwen-vl-plus"       # è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆçœ‹å›¾ç”Ÿæ–‡ï¼‰
LLM_MODEL = "qwen-turbo"         # çº¯æ–‡æœ¬æ¨¡å‹ï¼ˆæ”¹å†™å¤æ–‡ï¼‰

IMAGE_DIR = Path("data/images")
METADATA_FILE = Path("data/image_metadata.jsonl")
OUTPUT_FILE = Path("data/annotations.json")

# API è°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰ï¼Œé¿å…è§¦å‘é¢‘ç‡é™åˆ¶
API_DELAY = 1.5


def init_client():
    """åˆå§‹åŒ– OpenAI å…¼å®¹å®¢æˆ·ç«¯"""
    try:
        from openai import OpenAI
    except ImportError:
        print("âŒ ç¼ºå°‘ openai åº“ï¼Œæ­£åœ¨å®‰è£…...")
        os.system(f"{sys.executable} -m pip install openai")
        from openai import OpenAI

    return OpenAI(api_key=API_KEY, base_url=API_BASE)


def image_to_base64(image_path: Path) -> str:
    """å°†å›¾ç‰‡è½¬ä¸º base64 å­—ç¬¦ä¸²"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")


def get_image_mime(image_path: Path) -> str:
    """æ ¹æ®åç¼€æ¨æ–­ MIME ç±»å‹"""
    suffix = image_path.suffix.lower()
    return {
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".png": "image/png",
        ".webp": "image/webp",
        ".tiff": "image/tiff",
        ".tif": "image/tiff",
    }.get(suffix, "image/jpeg")


def build_vlm_prompt(meta: dict) -> str:
    """
    æ ¹æ® metadata æ„å»º VLM promptã€‚
    metadata æä¾›èƒŒæ™¯ä¿¡æ¯ï¼Œè®© VLM ä¸åªæ˜¯"ç›²çœ‹"å›¾ç‰‡ï¼Œ
    è€Œæ˜¯åœ¨çŸ¥é“ä½œå“æ ‡é¢˜ã€æœä»£ç­‰ä¿¡æ¯çš„å‰æä¸‹åšæ›´ç²¾å‡†çš„æè¿°ã€‚
    """
    context_parts = []

    era = meta.get("era", "")
    category = meta.get("category", "")
    title = meta.get("title", "")
    artist = meta.get("artist", "")
    description = meta.get("description", "")

    # ä» Wikimedia çš„ categories æ¨æ–­æ—¶ä»£å’Œç±»å‹
    categories = meta.get("categories", [])
    categories_str = ", ".join(categories[:5]) if categories else ""

    if title:
        context_parts.append(f"è¿™å¹…ä½œå“çš„æ ‡é¢˜/åç§°æ˜¯ï¼š{title}")
    if era:
        context_parts.append(f"å¹´ä»£ï¼š{era}")
    if artist:
        context_parts.append(f"ä½œè€…ï¼š{artist}")
    if category:
        context_parts.append(f"ç±»åˆ«ï¼š{category}")
    if description:
        context_parts.append(f"å·²çŸ¥ä¿¡æ¯ï¼š{description[:200]}")
    if categories_str:
        context_parts.append(f"ç›¸å…³æ ‡ç­¾ï¼š{categories_str}")

    context = "\n".join(context_parts) if context_parts else "ï¼ˆæ— å·²çŸ¥èƒŒæ™¯ä¿¡æ¯ï¼‰"

    return f"""ä½ æ˜¯ä¸€ä½å—å®‹å†å²ä¸è‰ºæœ¯ç ”ç©¶ä¸“å®¶ã€‚ä»¥ä¸‹æ˜¯å…³äºè¿™å¹…å›¾åƒçš„èƒŒæ™¯ä¿¡æ¯ï¼š

{context}

è¯·æ ¹æ®å›¾åƒå†…å®¹å’ŒèƒŒæ™¯ä¿¡æ¯ï¼Œç”Ÿæˆä»¥ä¸‹ 3 ç§æ–‡æœ¬æè¿°ï¼š

1. **ç°ä»£ä¸­æ–‡æè¿°**ï¼ˆmodern_chineseï¼‰ï¼š50-100å­—ï¼Œå®¢è§‚æè¿°ç”»é¢å†…å®¹ï¼ŒåŒ…å«è§†è§‰å…ƒç´ ï¼ˆæ„å›¾ã€è‰²å½©ã€ç‰©è±¡ï¼‰å’Œæ–‡åŒ–æ„ä¹‰ã€‚
2. **å¤æ–‡é£æ ¼æè¿°**ï¼ˆancient_styleï¼‰ï¼š30-80å­—ï¼Œæ¨¡ä»¿å®‹ä»£ç¬”è®°ä½“ï¼ˆå¦‚ã€Šæ¢¦æ¢å½•ã€‹é£æ ¼ï¼‰ï¼Œç”¨æ–‡è¨€æ–‡æè¿°ç”»é¢ã€‚
3. **æ£€ç´¢å…³é”®è¯**ï¼ˆkeywordsï¼‰ï¼š5-8ä¸ªç”¨é€—å·åˆ†éš”çš„å…³é”®è¯ï¼Œæ¶µç›–æœä»£ã€é¢˜æã€æŠ€æ³•ã€åœ°ç‚¹ç­‰ç»´åº¦ã€‚

è¯·ä¸¥æ ¼ä»¥ JSON æ ¼å¼è¾“å‡ºï¼Œç¤ºä¾‹ï¼š
{{
  "modern_chinese": "è¿™å¹…å—å®‹å±±æ°´ç”»æç»˜äº†è¥¿æ¹–çƒŸæ³¢æµ©æ¸ºçš„æ™¯è‰²...",
  "ancient_style": "æ¹–å±±æ¸…è¿œï¼ŒçƒŸæ³¢æµ©æ¸ºï¼ŒèˆŸæ¥«å¾€æ¥å¦‚ç»‡...",
  "keywords": "å—å®‹, å±±æ°´ç”», è¥¿æ¹–, é’ç»¿å±±æ°´, ç»¢æœ¬è®¾è‰²"
}}"""


def call_vlm(client, image_path: Path, prompt: str) -> dict:
    """è°ƒç”¨é€šä¹‰åƒé—® VLï¼Œè¾“å…¥å›¾ç‰‡+æ–‡å­—ï¼Œè¿”å›ç»“æ„åŒ–æè¿°"""
    b64 = image_to_base64(image_path)
    mime = get_image_mime(image_path)

    try:
        response = client.chat.completions.create(
            model=VLM_MODEL,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{mime};base64,{b64}"
                            }
                        },
                        {
                            "type": "text",
                            "text": prompt
                        }
                    ]
                }
            ],
            temperature=0.7,
            max_tokens=800,
        )

        text = response.choices[0].message.content.strip()

        # å°è¯•è§£æ JSONï¼ˆå¤„ç†å¯èƒ½çš„ markdown ä»£ç å—åŒ…è£¹ï¼‰
        if "```json" in text:
            text = text.split("```json")[1].split("```")[0].strip()
        elif "```" in text:
            text = text.split("```")[1].split("```")[0].strip()

        return json.loads(text)

    except json.JSONDecodeError:
        print(f"    âš ï¸ JSON è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬ä½œä¸ºæè¿°")
        return {
            "modern_chinese": text[:200] if text else "æè¿°ç”Ÿæˆå¤±è´¥",
            "ancient_style": "",
            "keywords": ""
        }
    except Exception as e:
        print(f"    âŒ VLM è°ƒç”¨å¤±è´¥: {e}")
        return None


def load_metadata() -> dict:
    """åŠ è½½ image_metadata.jsonlï¼Œè¿”å› filename -> metadata çš„æ˜ å°„"""
    meta_map = {}
    if METADATA_FILE.exists():
        with open(METADATA_FILE, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                entry = json.loads(line)
                fname = entry.get("filename", "")
                if fname:
                    meta_map[fname] = entry
    return meta_map


def get_all_images() -> list:
    """è·å– data/images/ ä¸‹æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶"""
    exts = {".jpg", ".jpeg", ".png", ".webp", ".tiff", ".tif"}
    images = []
    if IMAGE_DIR.exists():
        for p in sorted(IMAGE_DIR.iterdir()):
            if p.suffix.lower() in exts and p.is_file():
                images.append(p)
    return images


def main():
    import sys
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    parser = argparse.ArgumentParser(description="VLM è‡ªåŠ¨æ ‡æ³¨å—å®‹æ–‡åŒ–å›¾ç‰‡")
    parser.add_argument("--limit", type=int, default=None, help="åªå¤„ç†å‰ N å¼ å›¾ç‰‡ï¼ˆæµ‹è¯•ç”¨ï¼‰")
    parser.add_argument("--skip-existing", action="store_true", default=True, help="è·³è¿‡å·²æ ‡æ³¨çš„å›¾ç‰‡")
    args = parser.parse_args()

    # æ£€æŸ¥ API Key
    if not API_KEY or API_KEY == "YOUR_API_KEY_HERE":
        print("âŒ è¯·è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡æˆ–ä¿®æ”¹è„šæœ¬ä¸­çš„ API_KEY")
        print("   è·å–åœ°å€: https://bailian.console.aliyun.com/")
        sys.exit(1)

    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    print("ğŸ”§ åˆå§‹åŒ– API å®¢æˆ·ç«¯...")
    client = init_client()

    # åŠ è½½ metadata
    meta_map = load_metadata()
    print(f"ğŸ“‹ åŠ è½½ metadata: {len(meta_map)} æ¡è®°å½•")

    # è·å–å›¾ç‰‡åˆ—è¡¨
    images = get_all_images()
    if not images:
        print(f"âŒ data/images/ ç›®å½•ä¸‹æ²¡æœ‰å›¾ç‰‡")
        print(f"   è¯·å…ˆè¿è¡Œ: python scripts/scrape_wikimedia.py")
        sys.exit(1)

    if args.limit:
        images = images[:args.limit]
    print(f"ğŸ–¼ï¸ å¾…å¤„ç†å›¾ç‰‡: {len(images)} å¼ \n")

    # åŠ è½½å·²æœ‰æ ‡æ³¨ï¼ˆæ”¯æŒæ–­ç‚¹ç»­åšï¼‰
    existing = {}
    if OUTPUT_FILE.exists():
        with open(OUTPUT_FILE, "r", encoding="utf-8") as f:
            existing_list = json.load(f)
            for entry in existing_list:
                existing[entry.get("filename", "")] = entry
        print(f"ğŸ“‚ å·²æœ‰ {len(existing)} æ¡æ ‡æ³¨ï¼Œæ–­ç‚¹ç»­åš\n")

    results = list(existing.values())
    new_count = 0

    for i, img_path in enumerate(images):
        filename = img_path.name

        # è·³è¿‡å·²å¤„ç†çš„
        if args.skip_existing and filename in existing:
            continue

        print(f"[{i+1}/{len(images)}] æ ‡æ³¨: {filename}")

        # è·å– metadataï¼ˆå¯èƒ½æ²¡æœ‰ï¼Œåˆ™ç”¨é»˜è®¤å€¼ï¼‰
        meta = meta_map.get(filename, {"title": filename, "description": ""})

        # æ„å»º prompt å¹¶è°ƒç”¨ VLM
        prompt = build_vlm_prompt(meta)
        vlm_result = call_vlm(client, img_path, prompt)

        if vlm_result is None:
            print(f"    â­ï¸ è·³è¿‡ï¼ˆè°ƒç”¨å¤±è´¥ï¼‰")
            continue

        # ç»„è£…æ ‡æ³¨ç»“æœ
        annotation = {
            "filename": filename,
            "image_path": str(img_path),
            "title": meta.get("title", filename),
            "era": meta.get("era", ""),
            "category": meta.get("category", ""),
            "source": meta.get("source", ""),
            "modern_chinese": vlm_result.get("modern_chinese", ""),
            "ancient_style": vlm_result.get("ancient_style", ""),
            "keywords": vlm_result.get("keywords", ""),
        }

        results.append(annotation)
        new_count += 1
        print(f"    âœ… ç°ä»£: {annotation['modern_chinese'][:50]}...")
        print(f"    âœ… å¤æ–‡: {annotation['ancient_style'][:50]}...")

        # æ¯å¤„ç† 5 å¼ ä¿å­˜ä¸€æ¬¡ï¼ˆé˜²æ­¢ä¸­æ–­ä¸¢å¤±ï¼‰
        if new_count % 5 == 0:
            with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"    ğŸ’¾ è¿›åº¦ä¿å­˜ï¼ˆ{len(results)} æ¡ï¼‰")

        # API è°ƒç”¨é—´éš”
        time.sleep(API_DELAY)

    # æœ€ç»ˆä¿å­˜
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ‰ æ ‡æ³¨å®Œæˆï¼")
    print(f"   æ–°å¢æ ‡æ³¨: {new_count} æ¡")
    print(f"   æ€»è®¡æ ‡æ³¨: {len(results)} æ¡")
    print(f"   è¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE.resolve()}")

    # æ‰“å°æ ·ä¾‹
    if results:
        sample = results[-1]
        print(f"\nğŸ“ æœ€åä¸€æ¡æ ·ä¾‹:")
        print(f"   æ–‡ä»¶: {sample['filename']}")
        print(f"   ç°ä»£: {sample['modern_chinese'][:80]}")
        print(f"   å¤æ–‡: {sample['ancient_style'][:80]}")
        print(f"   å…³é”®è¯: {sample['keywords']}")


if __name__ == "__main__":
    main()
