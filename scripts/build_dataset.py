# -*- coding: utf-8 -*-
"""
å°† annotations.json è½¬æ¢ä¸º Chinese-CLIP è®­ç»ƒæ‰€éœ€çš„æ ¼å¼ï¼š
  - {split}_imgs.tsv    (image_id \t base64)
  - {split}_texts.jsonl ({"text_id", "text", "image_ids"})
ç„¶åè°ƒç”¨ build_lmdb_dataset.py ç”Ÿæˆ LMDBã€‚

ä½¿ç”¨æ–¹æ³•:
    conda activate pytorch
    cd d:/Desktop/CV/CLIP/NanS-CLIP
    python scripts/build_dataset.py
"""

import json
import base64
import random
import argparse
import logging
from pathlib import Path
from io import BytesIO
from PIL import Image

# ============ æ—¥å¿—é…ç½® ============
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# ============ é…ç½® ============
ANNOTATION_FILE = Path("data/annotations.json")
AUGMENTED_FILE = Path("data/annotations_augmented.json")
IMAGE_DIR = Path("data/images")
OUTPUT_DIR = Path("../clip_data/datasets/SongDynasty")  # Chinese-CLIP çº¦å®š
TRAIN_RATIO = 0.8


def image_to_base64(image_path: Path, max_size: int = 512) -> str:
    """å°†å›¾ç‰‡å‹ç¼©å¹¶è½¬ä¸º base64ï¼ˆèŠ‚çœ LMDB ç©ºé—´ï¼‰"""
    img = Image.open(image_path).convert("RGB")

    # ç­‰æ¯”ç¼©æ”¾åˆ° max_size
    w, h = img.size
    if max(w, h) > max_size:
        ratio = max_size / max(w, h)
        img = img.resize((int(w * ratio), int(h * ratio)), Image.LANCZOS)

    buf = BytesIO()
    img.save(buf, format="JPEG", quality=85)
    return base64.b64encode(buf.getvalue()).decode("utf-8")


def build_texts_for_image(ann: dict) -> list:
    """
    ä»ä¸€æ¡æ ‡æ³¨ç”Ÿæˆå¤šæ¡ text è®°å½•ã€‚
    """
    texts = []

    # 1. ç°ä»£ä¸­æ–‡æè¿°
    modern = ann.get("modern_chinese", "").strip()
    if modern:
        texts.append(modern)

    # 2. å¤æ–‡é£æ ¼æè¿°
    ancient = ann.get("ancient_style", "").strip()
    if ancient:
        texts.append(ancient)

    # 3. å…³é”®è¯ç»„åˆä¸ºä¸€å¥è¯ï¼ˆæ›´é€‚åˆ CLIP çš„çŸ­æ–‡æœ¬ç¼–ç ï¼‰
    keywords = ann.get("keywords", "").strip()
    if keywords:
        # "å—å®‹, å±±æ°´ç”», è¥¿æ¹–" â†’ "å—å®‹ å±±æ°´ç”» è¥¿æ¹–"
        kw_text = keywords.replace(",", " ").replace("ï¼Œ", " ").strip()
        texts.append(kw_text)

    # 4. æ ‡é¢˜æœ¬èº«ä¹Ÿæ˜¯ä¸€æ¡æ–‡æœ¬
    title = ann.get("title", "").strip()
    if title and title not in texts:
        texts.append(title)

    return texts


def main():
    parser = argparse.ArgumentParser(description="æ„å»º Chinese-CLIP æ•°æ®é›†")
    parser.add_argument("--annotation", type=str, default=str(ANNOTATION_FILE))
    parser.add_argument("--augmented", type=str, default=str(AUGMENTED_FILE))
    parser.add_argument("--aug_weight", type=float, default=0.3, help="æ‰©å¢æ–‡æœ¬çš„é™é‡‡æ ·æ¯”ä¾‹ (0.0~1.0)")
    parser.add_argument("--image_dir", type=str, default=str(IMAGE_DIR))
    parser.add_argument("--output_dir", type=str, default=str(OUTPUT_DIR))
    parser.add_argument("--train_ratio", type=float, default=TRAIN_RATIO)
    parser.add_argument("--seed", type=int, default=42)
    args = parser.parse_args()

    random.seed(args.seed)
    annotation_file = Path(args.annotation)
    augmented_file = Path(args.augmented)
    image_dir = Path(args.image_dir)
    output_dir = Path(args.output_dir)

    # 1. åŠ è½½ä¸»æ ‡æ³¨
    with open(annotation_file, "r", encoding="utf-8") as f:
        annotations = json.load(f)
    logger.info(f"åŠ è½½ä¸»æ ‡æ³¨: {len(annotations)} æ¡")

    # 2. åŠ è½½æ‰©å¢æ ‡æ³¨ï¼ˆå¯é€‰ï¼‰
    if augmented_file.exists():
        with open(augmented_file, "r", encoding="utf-8") as f:
            aug_anns = json.load(f)
        logger.info(f"åŠ è½½æ‰©å¢æ ‡æ³¨: {len(aug_anns)} æ¡ (é‡‡æ ·ç‡: {args.aug_weight})")
        
        # é™é‡‡æ ·è¿‡æ»¤
        sampled_augs = [
            ann for ann in aug_anns 
            if random.random() < args.aug_weight
        ]
        logger.info(f"é™é‡‡æ ·åæ‰©å¢ä¿ç•™: {len(sampled_augs)} æ¡")
        
        # åˆå¹¶éå°±ç»ªå­—å…¸ï¼šä¸ºäº†åŒºåˆ†ï¼Œç»™æ‰©å¢æ•°æ®æ‰“ä¸ª tag
        for ann in sampled_augs:
            ann["_is_augmented"] = True
        annotations.extend(sampled_augs)

    # è¿‡æ»¤æ‰æ²¡æœ‰å›¾ç‰‡æ–‡ä»¶çš„è®°å½•
    valid = []
    for ann in annotations:
        img_path = image_dir / ann["filename"]
        if img_path.exists():
            valid.append(ann)
        else:
            if not ann.get("_is_augmented", False): # ä»…æŠ¥å‘Šä¸»æ•°æ®ç¼ºå¤±
                logger.warning(f"å›¾ç‰‡ä¸å­˜åœ¨ï¼Œè·³è¿‡: {ann['filename']}")
    logger.info(f"æœ‰æ•ˆè®°å½•æ€»è®¡: {len(valid)} æ¡")

    if len(valid) < 5:
        logger.error("å›¾ç‰‡æ•°é‡å¤ªå°‘ï¼ˆ<5ï¼‰ï¼Œæ— æ³•æ„å»ºæœ‰æ•ˆæ•°æ®é›†")
        return

    # æ‰“ä¹±å¹¶æŒ‰ **å›¾ç‰‡** åˆ’åˆ† train/valid é¿å…æ³„éœ²
    # åŒä¸€å¼ å›¾ç‰‡çš„æ‰€æœ‰å˜ä½“æè¿°åªä¼šåˆ†åˆ°åŒä¸€è¾¹
    unique_filenames = list(set([ann["filename"] for ann in valid]))
    random.shuffle(unique_filenames)
    
    split_img_idx = int(len(unique_filenames) * args.train_ratio)
    train_filenames = set(unique_filenames[:split_img_idx])
    
    splits = {
        "train": [ann for ann in valid if ann["filename"] in train_filenames],
        "valid": [ann for ann in valid if ann["filename"] not in train_filenames],
    }
    
    logger.info(f"æŒ‰å›¾ç‰‡åˆ‡åˆ†: è®­ç»ƒé›† {len(train_filenames)} å›¾ | éªŒè¯é›† {len(unique_filenames) - len(train_filenames)} å›¾")
    logger.info(f"è®°å½•åˆ‡åˆ†: è®­ç»ƒé›† {len(splits['train'])} æ¡ | éªŒè¯é›† {len(splits['valid'])} æ¡")

    # ç”Ÿæˆæ•°æ®æ–‡ä»¶
    output_dir.mkdir(parents=True, exist_ok=True)

    for split_name, split_data in splits.items():
        tsv_path = output_dir / f"{split_name}_imgs.tsv"
        jsonl_path = output_dir / f"{split_name}_texts.jsonl"

        text_id_counter = 0

        # ç”±äºå¯èƒ½æœ‰å¤šæ¡æ ‡æ³¨å¯¹åº”åŒä¸€å¼ å›¾ï¼ˆè™½ç„¶ä¸Šé¢çš„å¤„ç†ä¿è¯äº†åŒä¸€å›¾éƒ½åœ¨åŒä¸€ä¸ª splitï¼‰ï¼Œ
        # æˆ‘ä»¬éœ€è¦åœ¨ç”Ÿæˆ TSV æ—¶æŒ‰å»é‡çš„å›¾ç‰‡å†™å…¥ä»¥é˜²æŠ¥é”™ã€‚
        # å»ºç«‹å»é‡æ˜ å°„
        split_unique_ann = []
        seen = set()
        for ann in split_data:
            if ann["filename"] not in seen:
                split_unique_ann.append(ann)
                seen.add(ann["filename"])

        with open(tsv_path, "w", encoding="utf-8") as f_tsv, \
             open(jsonl_path, "w", encoding="utf-8") as f_jsonl:

            # éå†å»é‡åçš„å›¾ç‰‡
            for image_id, ann_master in enumerate(split_unique_ann):
                img_path = image_dir / ann_master["filename"]

                # å†™ TSVï¼ˆå›¾ç‰‡ base64ï¼‰
                try:
                    b64 = image_to_base64(img_path)
                    f_tsv.write(f"{image_id}\t{b64}\n")
                except Exception as e:
                    logger.warning(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {ann_master['filename']}: {e}")
                    continue

                # æ”¶é›†æ‰€æœ‰æ­¤å›¾ç‰‡çš„æ ‡æ³¨
                ann_list = [a for a in split_data if a["filename"] == ann_master["filename"]]
                
                # å†™ JSONL
                for ann in ann_list:
                    texts = build_texts_for_image(ann)
                    for text in texts:
                        entry = {
                            "text_id": text_id_counter,
                            "text": text,
                            "image_ids": [image_id]
                        }
                        f_jsonl.write(json.dumps(entry, ensure_ascii=False) + "\n")
                        text_id_counter += 1

        logger.info(f"âœ… {split_name}: {len(split_unique_ann)} å›¾ | {text_id_counter} æ–‡æœ¬å¯¹")
        logger.info(f"   -> {tsv_path}")
        logger.info(f"   -> {jsonl_path}")

    logger.info(f"ğŸ“ æ•°æ®æ–‡ä»¶è¾“å‡ºå®Œæ¯•: {output_dir.resolve()}")
    logger.info(f"ä¸‹ä¸€æ­¥å»ºè®®è¿è¡Œ: python cn_clip/preprocess/build_lmdb_dataset.py --data_dir {output_dir} --splits train,valid")


if __name__ == "__main__":
    main()
