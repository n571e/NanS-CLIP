# -*- coding: utf-8 -*-
"""
å°† annotations.json è½¬æ¢ä¸º Chinese-CLIP è®­ç»ƒæ‰€éœ€çš„æ ¼å¼ï¼š
  - {split}_imgs.tsv    (image_id \t base64)
  - {split}_texts.jsonl ({"text_id", "text", "image_ids"})
ç„¶åè°ƒç”¨ build_lmdb_dataset.py ç”Ÿæˆ LMDBã€‚

ä½¿ç”¨æ–¹æ³•:
    conda activate pytorch
    cd d:/Desktop/CV/CLIP/NanS-CLIP
    python scripts/build_dataset.py
"""

import json
import base64
import random
import argparse
from pathlib import Path
from io import BytesIO
from PIL import Image

# ============ é…ç½® ============
ANNOTATION_FILE = Path("data/annotations.json")
IMAGE_DIR = Path("data/images")
OUTPUT_DIR = Path("../clip_data/datasets/SongDynasty")  # Chinese-CLIP çº¦å®š
TRAIN_RATIO = 0.8


def image_to_base64(image_path: Path, max_size: int = 512) -> str:
    """å°†å›¾ç‰‡å‹ç¼©å¹¶è½¬ä¸º base64ï¼ˆèŠ‚çœ LMDB ç©ºé—´ï¼‰"""
    img = Image.open(image_path).convert("RGB")

    # ç­‰æ¯”ç¼©æ”¾åˆ° max_size
    w, h = img.size
    if max(w, h) > max_size:
        ratio = max_size / max(w, h)
        img = img.resize((int(w * ratio), int(h * ratio)), Image.LANCZOS)

    buf = BytesIO()
    img.save(buf, format="JPEG", quality=85)
    return base64.b64encode(buf.getvalue()).decode("utf-8")


def build_texts_for_image(ann: dict, image_id: int) -> list:
    """
    ä»ä¸€æ¡æ ‡æ³¨ç”Ÿæˆå¤šæ¡ text è®°å½•ã€‚
    æ¯æ¡ text éƒ½å…³è”åˆ°åŒä¸€ä¸ª image_idã€‚
    """
    texts = []

    # 1. ç°ä»£ä¸­æ–‡æè¿°
    modern = ann.get("modern_chinese", "").strip()
    if modern:
        texts.append(modern)

    # 2. å¤æ–‡é£æ ¼æè¿°
    ancient = ann.get("ancient_style", "").strip()
    if ancient:
        texts.append(ancient)

    # 3. å…³é”®è¯ç»„åˆä¸ºä¸€å¥è¯ï¼ˆæ›´é€‚åˆ CLIP çš„çŸ­æ–‡æœ¬ç¼–ç ï¼‰
    keywords = ann.get("keywords", "").strip()
    if keywords:
        # "å—å®‹, å±±æ°´ç”», è¥¿æ¹–" â†’ "å—å®‹ å±±æ°´ç”» è¥¿æ¹–"
        kw_text = keywords.replace(",", " ").replace("ï¼Œ", " ").strip()
        texts.append(kw_text)

    # 4. æ ‡é¢˜æœ¬èº«ä¹Ÿæ˜¯ä¸€æ¡æ–‡æœ¬
    title = ann.get("title", "").strip()
    if title and title not in texts:
        texts.append(title)

    return texts


def main():
    import sys
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    parser = argparse.ArgumentParser(description="æ„å»º Chinese-CLIP æ•°æ®é›†")
    parser.add_argument("--annotation", type=str, default=str(ANNOTATION_FILE))
    parser.add_argument("--image_dir", type=str, default=str(IMAGE_DIR))
    parser.add_argument("--output_dir", type=str, default=str(OUTPUT_DIR))
    parser.add_argument("--train_ratio", type=float, default=TRAIN_RATIO)
    parser.add_argument("--seed", type=int, default=42)
    args = parser.parse_args()

    annotation_file = Path(args.annotation)
    image_dir = Path(args.image_dir)
    output_dir = Path(args.output_dir)

    # åŠ è½½æ ‡æ³¨
    with open(annotation_file, "r", encoding="utf-8") as f:
        annotations = json.load(f)
    print(f"ğŸ“‹ åŠ è½½æ ‡æ³¨: {len(annotations)} æ¡")

    # è¿‡æ»¤æ‰æ²¡æœ‰å›¾ç‰‡æ–‡ä»¶çš„è®°å½•
    valid = []
    for ann in annotations:
        img_path = image_dir / ann["filename"]
        if img_path.exists():
            valid.append(ann)
        else:
            print(f"  âš ï¸ å›¾ç‰‡ä¸å­˜åœ¨ï¼Œè·³è¿‡: {ann['filename']}")
    print(f"   æœ‰æ•ˆè®°å½•: {len(valid)} æ¡")

    if len(valid) < 5:
        print("âŒ å›¾ç‰‡æ•°é‡å¤ªå°‘ï¼ˆ<5ï¼‰ï¼Œæ— æ³•æ„å»ºæœ‰æ•ˆæ•°æ®é›†")
        return

    # æ‰“ä¹±å¹¶åˆ’åˆ† train/valid
    random.seed(args.seed)
    random.shuffle(valid)
    split_idx = int(len(valid) * args.train_ratio)
    splits = {
        "train": valid[:split_idx],
        "valid": valid[split_idx:],
    }
    print(f"   è®­ç»ƒé›†: {len(splits['train'])} | éªŒè¯é›†: {len(splits['valid'])}")

    # ç”Ÿæˆæ•°æ®æ–‡ä»¶
    output_dir.mkdir(parents=True, exist_ok=True)

    for split_name, split_data in splits.items():
        tsv_path = output_dir / f"{split_name}_imgs.tsv"
        jsonl_path = output_dir / f"{split_name}_texts.jsonl"

        text_id_counter = 0

        with open(tsv_path, "w", encoding="utf-8") as f_tsv, \
             open(jsonl_path, "w", encoding="utf-8") as f_jsonl:

            for image_id, ann in enumerate(split_data):
                img_path = image_dir / ann["filename"]

                # å†™ TSVï¼ˆå›¾ç‰‡ base64ï¼‰
                try:
                    b64 = image_to_base64(img_path)
                    f_tsv.write(f"{image_id}\t{b64}\n")
                except Exception as e:
                    print(f"  âš ï¸ å›¾ç‰‡å¤„ç†å¤±è´¥: {ann['filename']}: {e}")
                    continue

                # å†™ JSONLï¼ˆå¤šæ¡æ–‡æœ¬ï¼Œéƒ½å…³è”åˆ°åŒä¸€ä¸ª image_idï¼‰
                texts = build_texts_for_image(ann, image_id)
                for text in texts:
                    entry = {
                        "text_id": text_id_counter,
                        "text": text,
                        "image_ids": [image_id]
                    }
                    f_jsonl.write(json.dumps(entry, ensure_ascii=False) + "\n")
                    text_id_counter += 1

        print(f"   âœ… {split_name}: {len(split_data)} å›¾ | {text_id_counter} æ–‡æœ¬å¯¹")
        print(f"      {tsv_path}")
        print(f"      {jsonl_path}")

    print(f"\nğŸ“ æ•°æ®æ–‡ä»¶è¾“å‡º: {output_dir.resolve()}")
    print(f"\nä¸‹ä¸€æ­¥ï¼šè¿è¡Œ LMDB è½¬æ¢:")
    print(f"  python cn_clip/preprocess/build_lmdb_dataset.py \\")
    print(f"    --data_dir {output_dir} --splits train,valid")


if __name__ == "__main__":
    main()
